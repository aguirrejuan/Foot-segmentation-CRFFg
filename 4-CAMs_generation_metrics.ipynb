{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U git+https://github.com/aguirrejuan/ConvRFF.git --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np \n",
    "import os \n",
    "from glob import glob\n",
    "import tensorflow as tf \n",
    "from tqdm import tqdm \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "\n",
    "from convRFF.class_activation_maps.cam_data import mimic_mmap\n",
    "from convRFF.class_activation_maps import load_model_from_run\n",
    "from convRFF.class_activation_maps import generator_output_model\n",
    "from convRFF.class_activation_maps import save_ouput_model_data\n",
    "from convRFF.class_activation_maps import get_path_run\n",
    "from convRFF.class_activation_maps.output_masked import DTYPE as dtype_out_masked\n",
    "\n",
    "from gcpds.image_segmentation.datasets.segmentation import InfraredThermalFeet\n",
    "from gcpds.image_segmentation.losses import DiceCoefficient\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "WANDB_PROJECT = 'thesis_experiments'\n",
    "ROOT_FOLDER = '/content/drive/MyDrive/Pruebas_Tesis/cam_data_refactor_database' #ROOT_FOLDER_TO_SAVE_CAMS\n",
    "api = wandb.Api()\n",
    "runs = api.runs(WANDB_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(name_dataset):\n",
    "    if 'test' in name_dataset:\n",
    "        name_dataset = '_'.join(name_dataset.split('_')[1::])\n",
    "    datasets = {\n",
    "                'infrared_thermal_feet':InfraredThermalFeet(split=[0.1,0.1],seed=42),\n",
    "                'infrared_thermal_feet_nodataaug':InfraredThermalFeet(split=[0.1,0.1],seed=42)}\n",
    "    return datasets[name_dataset]\n",
    "\n",
    "\n",
    "def get_path(dataset, id_run):\n",
    "    name_file = f'colab11_thesis_experiments_{id_run}_*/{dataset}_layercam.mimic_memmap'\n",
    "    file_path = os.path.join(ROOT_FOLDER, name_file)\n",
    "    file_path = glob(file_path)\n",
    "    if len(file_path) ==0:\n",
    "        return None \n",
    "    return file_path[0] \n",
    "\n",
    "\n",
    "\n",
    "def calculate_results(arr_mmap, layer, dataset, target_classes=[0,1]):\n",
    "    data = arr_mmap[layer]\n",
    "    len_ = len(data['info_instance'])\n",
    "    results = np.zeros((len_, 3, len(target_classes)))\n",
    "    type_nerves = []\n",
    "    for i, (img, mask_, *info) in enumerate(dataset):\n",
    "        *label, id_image = info\n",
    "        #print(id_image)\n",
    "        filter_ = np.argmax(data['info_instance'][:,1] == id_image)\n",
    "\n",
    "        name_nerve, id_img = data['info_instance'][filter_]\n",
    "        cam = data['cam'][filter_]\n",
    "\n",
    "        #img, mask_, label, id_image  = dataset.load_instance_by_id(id_img)\n",
    "        img = tf.image.resize(img, cam.shape[:2])\n",
    "        mask_ = tf.image.resize(mask_, cam.shape[:2])\n",
    "\n",
    "    \n",
    "        for target_class in target_classes:\n",
    "            #p,p, w,w, d\n",
    "            if len(target_classes) == 2:\n",
    "                mask = mask_ if target_class==1 else 1 - mask_\n",
    "            else:\n",
    "                mask = mask_[...,target_class][...,None]\n",
    "\n",
    "            cam_target = cam[...,target_class][...,None]\n",
    "\n",
    "            total_e = tf.reduce_sum(cam_target) + 1e-9\n",
    "            partial_e = tf.reduce_sum(mask*cam_target)/total_e\n",
    "            results[i, 0, target_class] = partial_e\n",
    "\n",
    "            N = tf.reduce_sum(mask)\n",
    "            vnorm = tf.reduce_sum(mask*cam_target)/N\n",
    "            results[i, 1, target_class] = vnorm\n",
    "\n",
    "            norm_cam = cam_target/(tf.reduce_max(cam_target)+1e-9)\n",
    "            dice = DiceCoefficient()(mask,norm_cam)\n",
    "            results[i,2,target_class] = dice \n",
    "            \n",
    "\n",
    "        type_nerves.append(name_nerve)\n",
    "        #results[:,1,:] = results[:,1,:]/(results[:,1,:].max(axis=1,keepdims=True)+1e-9)\n",
    "    return results, type_nerves\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_results_layers(arr_mmap, dataset, target_class):\n",
    "    layers = arr_mmap._keys.keys()\n",
    "    #layers = ['Res15_Conv02','Res17_Conv02']\n",
    "    results = {}\n",
    "    for layer in tqdm(layers):\n",
    "        r, type_nerves = calculate_results(arr_mmap, layer, dataset,target_class)\n",
    "        results.setdefault('layer',[]).extend([layer]*len(type_nerves))\n",
    "        #p (c1,c2,c3,...), w(c1,c2,c3,...), d\n",
    "        for i, metric in enumerate(['p','w','dice']):\n",
    "            for class_ in range(r.shape[2]):\n",
    "                results.setdefault(f'{metric}_{class_}',[]).extend(r[:,i,class_])                \n",
    "        results.setdefault('class',[]).extend(type_nerves)\n",
    "    return results \n",
    "\n",
    "\n",
    "def load_mimic_mmap(file_path, dtype):\n",
    "    return mimic_mmap(file_path, dtype=dtype, mode='r')\n",
    "\n",
    "def generate_data_frame_from_ids(ids, dataset, dtype,target_class, dataset_index=0):\n",
    "    dataset_obj = get_dataset(dataset)()[dataset_index]\n",
    "    for id_run in ids: \n",
    "        file_path = get_path(dataset, id_run)\n",
    "        if not file_path:\n",
    "            print(f'Id dosent exist: {id_run}')\n",
    "            continue \n",
    "        df_name = os.path.dirname(file_path)\n",
    "        df_name = os.path.join(df_name,f'{dataset}.csv')\n",
    "        name_model = '_'.join(os.path.split(os.path.dirname(file_path))[-1].split('_')[4::])\n",
    "        print(name_model, id_run)\n",
    "        if  not os.path.exists(df_name):\n",
    "            try:\n",
    "                arr_mmap = load_mimic_mmap(file_path, id_run)\n",
    "                results = get_results_layers(arr_mmap, dataset_obj,target_class)\n",
    "                results = pd.DataFrame(results)\n",
    "                results['id'] = id_run\n",
    "                results['model'] = name_model\n",
    "                results.to_csv(df_name, index=False)\n",
    "            except: \n",
    "                print(f'error code {id_run}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids1 = [run.id for run in runs if  run.state=='finished' and run.config['dataset'] == 'infrared_thermal_feet' and run.sweep.id == '6l60ok26']\n",
    "\n",
    "ids2 = [run.id for run in runs if  run.state=='finished' and run.config['dataset'] == 'infrared_thermal_feet_nodataaug' and run.sweep.id == 'hg11kida']\n",
    "\n",
    "\n",
    "ids = ids1 + ids2\n",
    "\n",
    "dataset = 'infrared_thermal_feet'\n",
    "DTYPE = np.dtype([('info_instance', 'U50', (121,2)),  \n",
    "                  ('cam', np.float32, (121,224, 224, 2))\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data_frame_from_ids(ids, dataset, DTYPE, target_class=[0,1], dataset_index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ecac4580000282c2e756f0a2ed7e1bddcf659b8e5adedd5a8afcded5ccbd45c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
